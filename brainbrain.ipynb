{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "brainbrain.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asoemardy/adhi-mating_ASL/blob/devin/brainbrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3d5fa36e31d4fcd49c53da4e90711bfdc1568f69",
        "_cell_guid": "a75c343f-7e88-4a6c-87c0-78a1e8e8bd3d",
        "id": "svk-HGMRIua4"
      },
      "source": [
        "# Intro\n",
        "Kaggle provides free access to NVidia K80 GPUs in kernels. This benchmark shows that **enabling a GPU to your Kernel results in a 12.5X speedup during training of a deep learning model.** \n",
        "\n",
        "This kernel was run with a GPU. I compare run-times to a kernel training the same model on a CPU [here](https://www.kaggle.com/dansbecker/benchmarking-model-training-with-a-cpu).\n",
        "\n",
        "The total run-time with a GPU is 994 seconds. The total run-time for the kernel with only a CPU is 13,419 seconds. This is a 12.5X speedup (total run-time with only a CPU is 13.5X as long).\n",
        "\n",
        "Limiting the comparison only to model training, we see a reduction from 13,378 seconds on CPU to 950 seconds with a GPU.  So the model training speed-up is a little over 13X.\n",
        "\n",
        "The exact speed-up varies based on a number of factors including model architecture, batch-size, input pipeline complexity, etc. That said, the GPU opens up much great possibilities in Kaggle kernels. \n",
        "\n",
        "If you want to use these GPU's for deep learning projects, you'll likely find our [Deep Learning Course](kaggle.com/learn/deep-learning) the fastest path around to get up to speed so you can run your own projects.  We're also adding new image processing datasets to our [Datasets platform](kaggle.com/datasets) and we always have many [Competitions](kaggle.com/competitions) for you to try out new ideas using these free GPU's.  \n",
        "\n",
        "The following text shows how to enable a GPU and gives details on the benchmark.\n",
        "\n",
        "\n",
        "# Adding a GPU\n",
        "We set up this kernel to run on a GPU by first opening the kernel controls.\n",
        "\n",
        "![Imgur](https://i.imgur.com/WY2p6bH.png)\n",
        "___\n",
        "Select the **Settings** tab. Then select the checkbox for **Enable GPU**. Verify the GPU is attached to your kernel in the console bar, where it should show **GPU ON** next to your resource usage metrics.\n",
        "\n",
        "![Imgur](https://i.imgur.com/F9Hd3DN.png)\n",
        "___\n",
        "*GPU backed instances have less CPU power and RAM. Moreover, many data science libraries cannot take advantage of a GPU.  So, GPU's will be valuable for some tasks (especially when using deep learning libraries like TensorFlow, Keras and PyTorch).  But you are better off without a GPU for most other tasks.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f8d282d5bda58a2b3303d2733da0f6484ff37df1",
        "_cell_guid": "3afc3c83-ac99-4402-ac88-d4d91fd5decd",
        "id": "PUSuQpsvIubB"
      },
      "source": [
        "# The data\n",
        "\n",
        "The dataset contains images with 29 different signs in American Sign Language. These are the 26 letters (A through Z) plus the signs for *space*, *delete* and *nothing*. Our model will view these images and learn to classify what sign is made in each image.\n",
        "\n",
        "Sample images below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m20_6SLjJinE",
        "outputId": "f1b387e3-ffe6-4885-cdc0-3548640d4719"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (54.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey3oXvHpLHUp",
        "outputId": "3026d815-961d-4ea9-b72e-0b3b54a52a2c"
      },
      "source": [
        "!kaggle datasets download -d grassknoted/asl-alphabet"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a334a3525c03f23a55668f55db390abca81eab20",
        "_kg_hide-output": true,
        "_cell_guid": "a5f1f752-8365-40a8-a849-8ab2ab34db63",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "oJcPeC2SIubC",
        "outputId": "c6f08dfb-399e-4afc-e010-b5d1c7b90bea"
      },
      "source": [
        "# Imports for Deep Learning\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# ensure consistency across runs\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(2)\n",
        "\n",
        "\n",
        "# Imports to view data\n",
        "import cv2\n",
        "from glob import glob\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import floor\n",
        "import random\n",
        "\n",
        "def plot_three_samples(letter):\n",
        "    print(\"Samples images for letter \" + letter)\n",
        "    base_path = '../input/asl_alphabet_train/asl_alphabet_train/'\n",
        "    img_path = base_path + letter + '/**'\n",
        "    path_contents = glob(img_path)\n",
        "    \n",
        "    plt.figure(figsize=(16,16))\n",
        "    imgs = random.sample(path_contents, 3)\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(cv2.imread(imgs[0]))\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(cv2.imread(imgs[1]))\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(cv2.imread(imgs[2]))\n",
        "    return\n",
        "\n",
        "plot_three_samples('A')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples images for letter A\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e852f16b0f6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mplot_three_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-e852f16b0f6b>\u001b[0m in \u001b[0;36mplot_three_samples\u001b[0;34m(letter)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_contents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m131\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x1152 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "_cell_guid": "55c4a665-6a03-419d-9868-68a4c9cbdf71",
        "_uuid": "b3ef9cdbfebfc6cde56519c9163d1f8aa604627e",
        "trusted": true,
        "id": "J85oPLOMIubD"
      },
      "source": [
        "plot_three_samples('B')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3c0043a20407434fa301f51565bb184b4b54cde3",
        "_cell_guid": "a6106ce0-3618-43c6-bf05-a8e64fb4cbdd",
        "id": "vkM9CtHHIubE"
      },
      "source": [
        "# Data Processing Set-Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "oMc7VNdaIubE"
      },
      "source": [
        "data_dir = \"../input/asl_alphabet_train/asl_alphabet_train\"\n",
        "target_size = (64, 64)\n",
        "target_dims = (64, 64, 3) # add channel for RGB\n",
        "n_classes = 29\n",
        "val_frac = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "data_augmentor = ImageDataGenerator(samplewise_center=True, \n",
        "                                    samplewise_std_normalization=True, \n",
        "                                    validation_split=val_frac)\n",
        "\n",
        "train_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=batch_size, shuffle=True, subset=\"training\")\n",
        "val_generator = data_augmentor.flow_from_directory(data_dir, target_size=target_size, batch_size=batch_size, subset=\"validation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1fab4c91abce8e388652ef9c4c3d3ed6a3489a7c",
        "_cell_guid": "15dc1ae0-bc4a-4988-9c8c-01a9f8b5524c",
        "id": "9T2qpt8fIubF"
      },
      "source": [
        "# Model Specification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "dc201ab00d5790a06511a86563920f90a3f8f2d5",
        "_cell_guid": "435128bc-b3cb-410e-85a7-3ef43748b3f8",
        "trusted": true,
        "id": "PQIiiQH4IubF"
      },
      "source": [
        "my_model = Sequential()\n",
        "my_model.add(Conv2D(64, kernel_size=4, strides=1, activation='relu', input_shape=target_dims))\n",
        "my_model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
        "my_model.add(Dropout(0.5))\n",
        "my_model.add(Conv2D(128, kernel_size=4, strides=1, activation='relu'))\n",
        "my_model.add(Conv2D(128, kernel_size=4, strides=2, activation='relu'))\n",
        "my_model.add(Dropout(0.5))\n",
        "my_model.add(Conv2D(256, kernel_size=4, strides=1, activation='relu'))\n",
        "my_model.add(Conv2D(256, kernel_size=4, strides=2, activation='relu'))\n",
        "my_model.add(Flatten())\n",
        "my_model.add(Dropout(0.5))\n",
        "my_model.add(Dense(512, activation='relu'))\n",
        "my_model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "my_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "254cf9f24aecdc1150f9dbb5e47e53d15362320c",
        "_cell_guid": "d8be6e96-7e26-4cf9-b8a8-f4a7074be4bf",
        "id": "V-52iWkpIubG"
      },
      "source": [
        "# Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "655cfaa648459d757a204d81269395591771c5fb",
        "_cell_guid": "545599f9-c500-40b9-9853-22105572d82e",
        "trusted": true,
        "id": "KbHUWjpPIubG"
      },
      "source": [
        "my_model.fit_generator(train_generator, epochs=5, validation_data=val_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9IO7hD6dIubG"
      },
      "source": [
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-rdKj9KmIubH"
      },
      "source": [
        "letter = 'A_test.jpg'\n",
        "base_path = '../input/asl_alphabet_test/asl_alphabet_test/'\n",
        "img_path = base_path + letter \n",
        "path_contents = glob(img_path)\n",
        "target_size = (64, 64)\n",
        "print(img_path)\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "\n",
        "img = image.load_img('../input/asl_alphabet_test/asl_alphabet_test/Z_test.jpg', target_size = target_size)\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis = 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zcaIwhJhIubH"
      },
      "source": [
        "my_model.predict_classes(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b4q1yGP5IubI"
      },
      "source": [
        "label_map = (train_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_HKctdwfIubI"
      },
      "source": [
        "label_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "inELxITeIubI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}